# Usage instructions

In this folder you can find the python scripts that you can use to create the ***dataset*** array for the Neural Net training.

### Algorithm

The **algorithm** creates keywords in 4 steps:
1. resample wav to *44100* Hz
2. normalize wav samples
3. cut wav when threshold is met
4. resample wav to *11025* Hz


### Steps to create DATASET

#### 1. Sync keywords with Firebase

**`sync_keywords.py`** syncs wavs between your local `true_recs` folder and the Firebase `bucket` (available at this address: `gs://fpgacademy-mlg.appspot.com/true_recs/`) using this logic:

- check if `true_recs` exists, otherwise create it
- download from `bucket` wavs **not** present in `true_recs`
- remove from `true_recs` wavs **not** present in `bucket`

Uses the `gsutil` utility from [Google Cloud](https://cloud.google.com/storage/docs/quickstart-gsutil).

###### EXECUTION OUTPUT

`true_recs` folder synced with Fireabase `bucket`.

###### Log Output

```
Firebase keywords: < # of wavs in bucket >
Local keywords (before sync): < # of wavs in true_recs before sync >

< sync execution >

FINISHED!
New keywords downloaded: < # of wavs downloaded during sync >
Keywords deleted: < # of wavs removed during sync >
Local keywords (after sync): < # of wavs in true_recs after sync >
```

#### 2. Create true set

**`create_true_set.py`** creates the true set using wav files from `true_recs` folder using the **algorithm**.

Checks if `arrays` folder exists, otherwise creates it.

N = # of wavs in `true_recs` folder.

###### EXECUTION OUTPUT

`true_set.npy` in `arrays` folder containing N keywords generated by algorithm.

True keyowrds are ordered using ASC alphabetic order of `true_recs` wavs.

Each true keyword is composed by **5500** samples.

`true_set.npy` is a *numpy array*.

`true_set.npy` array structure:

|1st dimension|
|---|
|#1 keyword (5500 items)|
|#2 keyword (5500 items)|
|...|
|#N keyword (5500 items)|

###### Log Output

```
Local wavs: < # of wavs in true_recs = N >

< algorithm iteration for each keyword >

Processed keywords: < # of iterations = # of wavs in true_recs = N >
TRUE_SET saved. Lenght: < # of keywords in true_set.npy = N >
```

#### 3. Create false set

**`create_false_set.py`** creates the false set using wav files from `false_recs` folder using the **algorithm**.

Checks if `arrays` folder exists, otherwise creates it.

Cuts wavs from `false_recs` in pieces of length **22000** samples.

M = # of pieces cutted.

###### EXECUTION OUTPUT

`false_set.npy` in `arrays` folder containing M keywords generated by algorithm.

Each false keyword is composed by **5500** samples.

`false_set.npy` is a *numpy array*.

`false_set.npy` array structure:

|1st dimension|
|---|
|#1 keyword (5500 items)|
|#2 keyword (5500 items)|
|...|
|#M keyword (5500 items)|

###### Log Output

```
< algorithm iteration for each piece >
False keyword generated: < # of iterations = # of false keywords generated = M >

FALSE_SET saved. Lenght: < # of keywords in false_set.npy = M >
```

#### 4. Create dataset

**`create_dataset.py`** creates the dataset using keywords both from `true_set.npy` and `false_set.npy` generated in the previous steps.

K = # of true keywords + # of false keywords = N + M

###### EXECUTION OUTPUT

`dataset.npy` in `arrays` folder containing .

Keyowrds are ordered **randomly**.

`dataset.npy` is a *numpy array*.

`dataset.npy` array structure

|X (1st dimension)|Y (2nd dimension)|
|---|:-:|
|#1 keyword (5500 items)|**1** if true keyword,**0** if false keyword|
|#2 keyword (5500 items)|"|
|...|"|
|#K keyword (5500 items)|"|

###### Log Output

```
< code execution >
True keywords: < # of true keywords = length of true_set array >
False keywords: < # of false keywords = length of false_set array >

Dataset X: < # of all keywords = K >
Dataset Y: < # of all keywords = K >
```
